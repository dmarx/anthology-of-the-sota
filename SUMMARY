================================================================================
File: .github/workflows/build-readme.yaml
================================================================================
name: Build README

on:
  push:
    paths:
      - 'docs/**'
      - '.github/workflows/build-readme.yaml'
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"

jobs:
  test:
    uses: ./.github/workflows/test.yml

  build-readme:
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip
      
      - name: Install package
        run: pip install llamero

      - name: Generate README
        run: |
          # llamero readme
          llamero tree
          llamero build_template docs/readme
          llamero build_template docs/readme_llm



================================================================================
File: .github/workflows/build_registry.yml
================================================================================
name: Build Registry

on:
  push:
    paths:
      - 'data/research.yaml'
      - 'src/scripts/registry/**'
      - './.github/workflows/build_registry.yml'
  workflow_dispatch:  # Allow manual triggering
  schedule:
    - cron: '0 0 * * 0'  # Run weekly on Sunday at midnight

jobs:
  # Add test job from test workflow
  test:
    uses: ./.github/workflows/test.yml
  
  build:
    needs: test  # Make build dependent on tests passing
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[all]"
      
      - name: Build registry
        run: python -m scripts.registry.cli build

      #- name: cp to readme section
        #run: |
          #cp data/registry.yaml docs/readme/sections/registry.md.j2
          #python -m scripts.registry.cli build # just run it again for the commit, fuck it
          # TODO: python -m scripts.utils.commit_and_push



================================================================================
File: .github/workflows/deploy-frontend.yaml
================================================================================
# File: .github/workflows/deploy-frontend.yaml
name: Deploy Frontend

on:
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - 'web/**'
      - 'data/registry.yaml'
      - '.github/workflows/deploy-frontend.yaml'

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Copy data file
        run: |
          mkdir -p web/data
          cp data/registry.yaml web/data/

      - name: Deploy to GitHub Pages
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          folder: web
          branch: gh-pages



================================================================================
File: .github/workflows/generate_summaries.yaml
================================================================================
name: Generate Directory Summaries

on:
  #push:
  workflow_dispatch:

jobs:
  generate-summaries:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install llamero
      run: pip install llamero

    - name: Generate summaries
      run: llamero summarize all



================================================================================
File: .github/workflows/render_svg.yaml
================================================================================
name: Convert Logo SVG to PNG

on:
  workflow_dispatch:  # Manual trigger
  push:
    paths:
      - 'assets/logo.svg'  # Only run when logo changes

jobs:
  convert:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Install Inkscape
        run: |
          sudo add-apt-repository -y universe
          sudo apt-get update
          sudo apt-get install -y inkscape
      
      - name: Convert SVG to PNG
        run: |
          mkdir -p assets
          inkscape --export-type=png --export-filename=assets/logo.png assets/logo.svg
      
      - name: Commit PNG if changed
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add assets/logo.png
          git diff --quiet && git diff --staged --quiet || git commit -m "Update logo.png from SVG source"
          git push



================================================================================
File: .github/workflows/test.yml
================================================================================
name: Tests

on:
  push:
    paths:
      - "src/**"
      - "tests/**"
      - ".github/workflows/test.yml"
  workflow_dispatch:
  workflow_call:
    
env:
  PYTHON_VERSION: "3.11"

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip
      
      - name: Install dependencies
        run: |
          pip install -e ".[all]"
      
      - name: Run tests
        run: |
          pytest tests/ -v



================================================================================
File: docs/readme/base.md.j2
================================================================================
{% for template in templates %}
{% include "sections/" ~ template %}

{% endfor %}



================================================================================
File: docs/readme/sections/introduction.md.j2
================================================================================
<p align="center">
  <img src="assets/logo.svg" width="200" height="200" alt="ML Training Phase Transitions">
</p>

<h1 align="center">Anthology of the SOTA</h1>

<p align="center">
  Best practices for ML/AI training, validated by research and experience
</p>

---

Why we -- AI/ML researchers and practitioners -- do the things that we do, and why we do those things the way that we do them.

You might also be interested in my list of significantly impactful works that has more of a historical perspective: https://github.com/dmarx/anthology-of-modern-ml

The main difference here is that where that prior list was focused on big, impactful works, including those which no longer reflect best practice, this list is focused entirely on whatever the current best practice is understood to be and explaining the justification behind that design choice. Where my `Modern ML` anthology focused on paradigm shifts and made no space for important but comparatively "small" (with respect to paradigmatic impact) incremental improvements, I expect this space to be dominated by incremental works. Additional, because the other list operates as a kind of "hall of fame", it generally should not experience churn. This list however, I plan to maintain as a living document with an "attic" in which to deprecate former best practices that have been supplanted.



================================================================================
File: docs/readme/sections/registry.md.j2
================================================================================
# ML Training Recommendations Registry

Last updated: 2024-12-01

## Experimental Recommendations


## Standard Recommendations

### MoE

- Use largest batch that maintains >80% sample efficiency

- Scale batch size with model size but sub-linearly

### attention

- Use flash attention for all attention computations when hardware supports it

- Tiling size should match hardware SRAM size

- Recompute attention during backward pass instead of storing it

- PagedAttention to accelerate batch inference for LLM sampling

- Use flash-attention-2 over original flash-attention when available

- Keep sequence lengths multiple of 128 for best performance

- Pad attention masks to block boundaries for better hardware utilization

- Prefer GQA to MQA or MHA
  - Implementations: llama2

### attention-alternatives

- Consider for very long sequence tasks

- Use for tasks where attention bottlenecks training

- Combine with standard attention for hybrid approaches

### checkpointing

- Checkpoint frequency should increase with training time

- Save optimizer state every N epochs (N ~ sqrt(total_epochs))

- Use async I/O for checkpoint writing

- Implement multi-level checkpoint strategy

### compilation

- Use operator fusion for small operations

- Optimize memory layout for hardware

- Implement custom kernels for critical ops

- Profile-guided optimization for hot paths

### data-loading

- Memory-map large datasets

- Use mixed precision during data loading

- Pin memory for CPU-GPU transfers

- Profile data loading separate from training

- Use tar archives for dataset storage

- Buffer size should be 2-3x batch size

- Pre-fetch next batch during compute

- Use multiple worker processes (num_workers = 4 * num_gpus)

### data-quality

- Use perplexity-based filtering for quality assessment

- Implement dynamic temperature scaling for mixing

- Adjust mixing ratios based on validation performance

- Monitor domain coverage during training

### distributed-training

- Use micro-batch splitting for pipeline parallelism

- Balance pipeline stages to minimize bubble overhead

- Choose pipeline chunks based on memory vs. compute trade-off

- Use hierarchical allreduce for tensors > 1MB

- Overlap communication with backward pass

- Group small tensors before communication

- Set buffer size to network bandwidth-delay product

- Use sequence parallelism for attention layers

- Overlap communication with computation when possible

- Initialize layer norms with smaller variance (0.02) for stability

- Monitor network utilization during training

- Adapt buffer sizes to network conditions

- Use gradient compression for slow networks

- Place replicas to minimize cross-rack traffic

- Use FSDP over DDP when model size exceeds single GPU memory

- Overlap communication with computation using backward prefetch

- Employ mixed precision to reduce memory usage

- Choose sharding factor based on model and GPU memory size

### hardware-optimization

- Fuse small operations into larger kernels

- Align tensor dimensions to hardware boundaries

- Use hardware-specific memory layouts

- Profile and optimize memory access patterns

### initialization

- Scale attention weights by 1/sqrt(head_dim)

- Initialize final layer weights near zero

- Use smaller variance for deep networks

- Special handling for gated architectures

### language-models

- continued pre-training for fine tuning

- gpt training recipe

- LM in-context learning emerges at scale

- ICL permits few-shot task adaptability

- single cycle of cosine decay is sufficient lr schedule

- smaller batch sizes are more sample efficient (i.e., better loss as a function of tokens seen) earlier in training
  - Implementations: PaLM

- larger batch sizes are beneficial later in training due to better gradient estimates
  - Implementations: PaLM

- throughput (energy efficiency) wins out over theoretically optimal sample efficiency
  - Implementations: PaLM

- consider rewinding to earlier checkpoint and skipping a few batches to mitigate unusual loss spikes
  - Implementations: PaLM

### large-batch-training

- linear warmup of LR stabilizes early training with large batch size.

### memory-efficiency

- Stage optimizer states across data parallel ranks (ZeRO-1)

- Partition gradients and optimizer states (ZeRO-2) for larger models

- Use ZeRO-3 only when other strategies insufficient

- Keep micro-batch size per GPU as large as memory allows

### nlp

- BPE tokenization for open vocabulary tasks
  - Implementations: llama2

### normalization

- Place BatchNorm after linear/conv layers but before activation functions

- Use running statistics for inference

- Consider alternatives like LayerNorm for transformers

- Use larger learning rates with batch normalization

- Monitor loss landscape smoothness during training

- Place BN after linear/conv layers but before activation functions

- Initialize LayerNorm weight close to 1 (0.97-1.0)

- Initialize LayerNorm bias to 0

- Use a smaller learning rate for LayerNorm parameters

### optimization

- Default choice for neural network training

- Common hyperparameters: β₁=0.9, β₂=0.999, ε=1e-8

- Learning rate typically 1e-4 to 1e-3 for most tasks

- warmup to a large early lr, anneal throughout training to small final lr

- skip connections promote training stability by smoothing out the loss landscape

- visualizing eigenvalues of hessian (ratio of largest to smallest) over training can be useful diagnostics

- sharpness in loss landscape corerlates with test error

- use gradient clipping

### scaling-laws

- larger models are more sample efficient

- lr tuning less important for larger models

- `num_tokens ~ 20 * num_params`
  - Implementations: chinchilla, llama2

- Optimal batch size scales approximately with compute budget - `B ∝ C^(1/4)`
  - Implementations: chinchilla, llama2

### systems

- Use continuous batching for inference

- Fuse attention operations where possible

- Overlap prefill and decode compute

### training-dynamics

- Warmup needed scales sub-linearly with model size
  - Implementations: vision_transformer, bert

- Initialize layer norm weights closer to 1 for larger models
  - Implementations: vision_transformer, bert

- Can use shorter warmup periods for wider models
  - Implementations: vision_transformer, bert

- Monitor loss specifically during first ~5000 steps for instabilities
  - Implementations: vision_transformer, bert

- Use gradient clipping during early training phase
  - Implementations: vision_transformer, bert

- Monitor validation loss for unexpected spikes during training

- Track gradient norm statistics to detect training instabilities

- Use learning rate warmup proportional to model size

### training-efficiency

- Use dynamic loss scaling that doubles every 2000 successful steps

- Maintain master weights in FP32

- Store optimizer states in FP32

- Perform forward/backward passes in FP16

### training-stability

- Use pre-norm (RMSNorm) for transformer layers
  - Implementations: llama2

- Monitor exp(loss) for stability

- Track gradient norm ratios between layers

- Use gradient clipping with dynamic threshold

- Implement early warning system for NaNs

### transformers

- Use multi-query attention for decoder-only models to reduce memory bandwidth

- Keep key/value projections shared across heads while query projections remain separate

- Use SwiGLU activation for transformers
  - Implementations: llama2

- use RoPE for LLM (1D sequence) positional embeddings


## Deprecated Recommendations


## Statistics

### optimization

- Total recommendations: 8
- Year range: 2014 - 2020

### normalization

- Total recommendations: 9
- Year range: 2015 - 2019

### nlp

- Total recommendations: 1
- Year range: 2015 - 2015

### large-batch-training

- Total recommendations: 1
- Year range: 2017 - 2017

### training-efficiency

- Total recommendations: 4
- Year range: 2017 - 2017

### distributed-training

- Total recommendations: 18
- Year range: 2018 - 2023

### transformers

- Total recommendations: 4
- Year range: 2019 - 2021

### memory-efficiency

- Total recommendations: 4
- Year range: 2020 - 2020

### training-stability

- Total recommendations: 5
- Year range: 2020 - 2021

### language-models

- Total recommendations: 9
- Year range: 2020 - 2022

### scaling-laws

- Total recommendations: 4
- Year range: 2020 - 2022

### data-loading

- Total recommendations: 8
- Year range: 2021 - 2021

### initialization

- Total recommendations: 4
- Year range: 2021 - 2021

### checkpointing

- Total recommendations: 4
- Year range: 2021 - 2021

### MoE

- Total recommendations: 2
- Year range: 2021 - 2021

### training-dynamics

- Total recommendations: 8
- Year range: 2021 - 2023

### compilation

- Total recommendations: 4
- Year range: 2022 - 2022

### attention

- Total recommendations: 8
- Year range: 2022 - 2023

### hardware-optimization

- Total recommendations: 4
- Year range: 2022 - 2022

### data-quality

- Total recommendations: 4
- Year range: 2023 - 2023

### attention-alternatives

- Total recommendations: 3
- Year range: 2023 - 2023

### systems

- Total recommendations: 3
- Year range: 2023 - 2023




================================================================================
File: docs/readme/sections/structure.md.j2
================================================================================
## Project Structure

```

├── .github
│   └── workflows
│       ├── build-readme.yaml
│       ├── build_registry.yml
│       ├── deploy-frontend.old
│       ├── deploy-frontend.yaml
│       ├── generate-package-lock.yaml
│       ├── generate_summaries.yaml
│       ├── render_svg.yaml
│       └── test.yml
├── .gitignore
├── LICENSE
├── README.llm
├── README.md
├── README_LLM.md
├── assets
│   └── logo.svg
├── assets.logo.svg
├── data
│   ├── REGISTRY.md
│   ├── registry.yaml
│   └── research.yaml
├── docs
│   ├── readme
│   │   ├── base.md.j2
│   │   └── sections
│   │       ├── introduction.md.j2
│   │       ├── registry.md.j2
│   │       └── structure.md.j2
│   └── readme_llm
│       ├── base.md.j2
│       └── sections
│           ├── development.md.j2
│           └── registry_naming_conventions.md.j2
├── frontend
│   ├── next.config.js
│   ├── package-lock.json
│   ├── package.json
│   ├── src
│   │   ├── components
│   │   │   └── recommendations
│   │   │       ├── ArxivLink
│   │   │       │   ├── ArxivLink.test.tsx
│   │   │       │   └── ArxivLink.tsx
│   │   │       ├── RecommendationCard
│   │   │       │   ├── RecommendationCard.test.tsx
│   │   │       │   └── RecommendationCard.tsx
│   │   │       ├── RelatedRecommendations
│   │   │       │   ├── RelatedRecommendations.test.tsx
│   │   │       │   └── RelatedRecommendations.tsx
│   │   │       └── SuccessionChain
│   │   │           ├── SuccessionChain.test.tsx
│   │   │           └── SuccessionChain.tsx
│   │   ├── pages
│   │   │   ├── 404.tsx
│   │   │   ├── 500.tsx
│   │   │   ├── _app.tsx
│   │   │   ├── _document.tsx
│   │   │   └── index.tsx
│   │   ├── styles
│   │   │   └── globals.css
│   │   ├── types
│   │   │   └── recommendations.ts
│   │   └── utils
│   │       └── recommendations.ts
│   └── tsconfig.json
├── pyproject.toml
├── src
│   └── scripts
│       ├── generate-package-lock.js
│       ├── generate_summaries
│       │   ├── __init__.py
│       │   ├── __main__.py
│       │   ├── generator.py
│       │   ├── signature_extractor.py
│       │   └── special_summaries.py
│       ├── readme_generator.py
│       ├── registry
│       │   ├── __init__.py
│       │   ├── cli.py
│       │   ├── identifiers.py
│       │   ├── io.py
│       │   ├── recommendations.py
│       │   └── types.py
│       └── utils.py
└── tests
    ├── conftest.py
    ├── registry
    │   ├── test_identifiers.py
    │   ├── test_io.py
    │   └── test_recommendations.py
    └── test_generate_readme.py

```



================================================================================
File: docs/readme_llm/base.md.j2
================================================================================
{% for template in templates %}
{% include "sections/" ~ template %}

{% endfor %}



================================================================================
File: docs/readme_llm/sections/development.md.j2
================================================================================
## Development Guidelines

### Code Organization for LLM Interaction

When developing this project (or using it as a template), keep in mind these guidelines for effective collaboration with Large Language Models:

1. **File Length and Modularity**
   - Keep files short and focused on a single responsibility
   - If you find yourself using comments like "... rest remains the same" or "... etc", the file is too long
   - Files should be completely replaceable in a single LLM interaction
   - Long files should be split into logical components

2. **Dependencies**
   - All dependencies managed in `pyproject.toml`
   - Optional dependencies grouped by feature:
     ```toml
     [project.optional-dependencies]
     test = ["pytest", ...]
     site = ["markdown2", ...]
     all = ["pytest", "markdown2", ...]  # Everything
     ```
   - Use appropriate groups during development:
     ```bash
     pip install -e ".[test]"  # Just testing
     pip install -e ".[all]"   # Everything
     ```

3. **Testing Standards**
   - Every new feature needs tests
   - Write tests before starting on new features to formalize expected behavior (i.e. TDD)
   - Tests should be clear and focused
   - Use pytest fixtures for common setups
   - All workflows depend on tests passing
   - Test files should follow same modularity principles
   - Use `pytest` fixtures for common setups
   - Keep tests focused and well-documented

4. **Why This Matters**
   - LLMs work best with clear, focused contexts
   - Complete file contents are better than partial updates with ellipsis
   - Tests provide clear examples of intended behavior
   - Shorter files make it easier for LLMs to:
     - Understand the complete context
     - Suggest accurate modifications
     - Maintain consistency
     - Avoid potential errors from incomplete information

5. **Best Practices**
   - Aim for files under 200 lines
   - Each file should have a single, clear purpose
   - Use directory structure to organize related components
   - Prefer many small files over few large files
   - Consider splitting when files require partial updates

6. **Project Conventions**
   - Use `loguru` for all logging
   - Use `fire` for CLI interfaces
   - use `omegaconf` for yaml
   - Prefer `pathlib` for file system operations
   - Type hints should use:
     - Built-in generics over typing module (PEP 585)
     - Union operator (`|`) over Optional (PEP 604)
   - Github Actions is the only available runtime for script execution
   - All workflows depend on tests passing
   - Syntax permitting, all files should begin with a comment detailing the current file's name and relative path within the project



================================================================================
File: docs/readme_llm/sections/registry_naming_conventions.md.j2
================================================================================
# ML Training Topics Organization

## Topic Structure

### 1. training-optimization
Consolidates training-related performance and methodology
- Previously covered by:
  - training-efficiency
  - training-dynamics
  - large-batch-training
  - optimization
  - scaling-laws
- Scope:
  - Learning rate schedules
  - Batch size optimization
  - Training dynamics monitoring
  - Optimization algorithms
  - Scaling strategies
  - General performance metrics

### 2. systems-optimization
Hardware and software system optimizations
- Previously covered by:
  - hardware-optimization
  - compilation
  - systems
- Scope:
  - Hardware utilization
  - Kernel optimization
  - Compilation strategies
  - Memory access patterns
  - System-level performance

### 3. model-stability
Model training stability and initialization
- Previously covered by:
  - training-stability
  - initialization
  - normalization (partially)
- Scope:
  - Initialization techniques
  - Normalization methods
  - Gradient handling
  - Training stability monitoring
  - Loss landscape analysis

### 4. distributed-optimization
Distributed training and memory management
- Previously covered by:
  - distributed-training
  - memory-efficiency
  - checkpointing
- Scope:
  - Distribution strategies
  - Memory management
  - Checkpointing
  - Communication optimization
  - Resource allocation

### 5. data-pipeline
Data handling and quality
- Previously covered by:
  - data-loading
  - data-quality
- Scope:
  - Data loading optimization
  - Quality assessment
  - Pipeline efficiency
  - Data preprocessing
  - Batch preparation

### 6. attention-techniques
Attention mechanism implementations
- Previously covered by:
  - attention
  - attention-alternatives
- Scope:
  - Attention variants
  - Implementation optimizations
  - Alternative mechanisms
  - Memory efficiency

### 7. model-architecture
Model-specific architectural patterns
- Previously covered by:
  - transformers
  - nlp
  - MoE
- Scope:
  - Architecture patterns
  - Component design
  - Model-specific optimizations
  - Structural choices

## Naming Conventions

1. **Format**: hyphenated-lowercase
   ```
   good: training-optimization
   bad: TrainingOptimization, training_optimization
   ```

2. **Process Topics**: Use gerund (-ing) form
   ```
   good: training-optimization, model-scaling
   bad: train-optimization, scale-models
   ```

3. **Component Topics**: Use noun form
   ```
   good: model-architecture, attention-techniques
   bad: modeling-architecture, attending-techniques
   ```

4. **Standard Suffixes**:
   - `-optimization`: Performance-focused topics
   - `-techniques`: Methodology-focused topics
   - `-architecture`: Structural topics
   - `-pipeline`: Process flow topics

## Migration Guide

1. **Recommendation Tagging**:
   - Each recommendation should be tagged with exactly one primary topic
   - Can have additional secondary topic tags if needed
   - Use most specific applicable topic

2. **Topic Metadata**:
   - Each topic should have:
     - Clear scope definition
     - Parent topic (if applicable)
     - Related topics
     - Key references

3. **Implementation Steps**:
   1. Create new topic structure
   2. Map existing recommendations to new topics
   3. Update all recommendation tags
   4. Add metadata to topics
   5. Review for consistency

## Topic Maintenance Rules

1. **Adding New Topics**:
   - Must follow naming conventions
   - Must have clear, non-overlapping scope
   - Must include scope definition and metadata
   - Should fit within existing hierarchy

2. **Merging Topics**:
   - Required when scope overlap exceeds 50%
   - Must migrate all recommendations
   - Must update all references

3. **Splitting Topics**:
   - Required when topic becomes too broad
   - Must have clear dividing criteria
   - Should maintain naming consistency

4. **Deprecating Topics**:
   - Mark as deprecated with reason
   - Migrate or archive recommendations
   - Maintain historical record



================================================================================
File: pyproject.toml
================================================================================
[project]
name = "scripts"
version = "0.1.0"
description = ""
requires-python = ">=3.11"
dependencies = [
    "Jinja2>=3.1.2",
    "tomli>=2.0.1",
    "loguru>=0.7.0",
    "fire>=0.5.0",
    "tree-format>=0.1.2",
    "pyyaml", # todo: deprecate in favor of omegaconf
    "omegaconf",
    "llamero"
]

[project.optional-dependencies]
test = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
]
site = [
    "markdown2>=2.4.0",
]
summary = [
    "loguru>=0.7.0",
    "fire>=0.5.0",
]
# Meta-dependency that includes everything
all = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
    "markdown2>=2.4.0",
]

[project.scripts]
build-registry = "scripts.registry.cli:cli"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/scripts"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
addopts = "-v --cov=readme_generator --cov=summary_generator"

[tool.readme.tree]
ignore_patterns = [
    "__pycache__",
    "*.pyc",
    ".git",
    ".venv",
    ".pytest_cache",
    ".vscode",
    ".idea",
    "*.egg-info",
    "*.pyc",
    "*.pyo",
    "*.pyd",
    ".Python",
    "*.so",
    ".gitkeep",
    "_version.py"
]

[tool.readme.sections.order]
"introduction.md.j2" = 0
"features.md.j2" = 1
"prerequisites.md.j2" = 2
"setup.md.j2" = 2.1
"installation.md.j2" = 2.2
"usage.md.j2" = 3
"development.md.j2" = 4
"summaries.md.j2" = 5
"site.md.j2" = 6
"structure.md.j2" = 7
"todo.md.j2" = 999

[tool.summary]
max_file_size_kb = 500  # Skip files larger than 1MB

# File patterns to exclude
exclude_patterns = [
    '.git',
    '.gitignore',
    '.pytest_cache',
    '__pycache__',
    'SUMMARY',
    '.coverage',
    '.env',
    '.venv',
    '.idea',
    '.vscode',
    'README.md',
    'README_LLM.md',
    'package-lock.json',
    'REGISTRY.md',
    'research.yaml',
    'registry.yaml',
    'bibliography',
    '.bibtex'
]

# File extensions to include
include_extensions = [
    '.py',
    '.md',
    '.txt',
    '.yml',
    '.yaml',
    '.toml',
    '.json',
    '.html',
    '.css',
    '.js',
    '.ts',
    '.tsx',
    '.j2'
]

# Directories to exclude
exclude_directories = [
    '.git',
    '__pycache__',
    '.pytest_cache',
    '.venv',
    '.idea',
    '.vscode',
    'data'
]



================================================================================
File: src/scripts/generate-package-lock.js
================================================================================
// src/scripts/generate-package-lock.js
const fs = require('fs');
const { execSync } = require('child_process');
const path = require('path');

function generatePackageLock() {
  const frontendDir = path.join(__dirname, '../../frontend');
  
  // Check if we need to generate package-lock.json
  if (!fs.existsSync(path.join(frontendDir, 'package-lock.json'))) {
    console.log('Generating package-lock.json...');
    
    try {
      // Run npm install to generate package-lock.json
      execSync('npm install', { 
        cwd: frontendDir,
        stdio: 'inherit'
      });
      
      console.log('Successfully generated package-lock.json');
    } catch (error) {
      console.error('Error generating package-lock.json:', error);
      process.exit(1);
    }
  } else {
    console.log('package-lock.json already exists');
  }
}

// Run if called directly
if (require.main === module) {
  generatePackageLock();
}

module.exports = generatePackageLock;



================================================================================
File: src/scripts/generate_summaries/__init__.py
================================================================================
"""Package for generating directory summaries to assist LLM interactions."""
from pathlib import Path
from typing import List

__version__ = "0.1.0"

# Re-export main functionality
from .generator import SummaryGenerator

__all__ = ["SummaryGenerator"]



================================================================================
File: src/scripts/generate_summaries/__main__.py
================================================================================
import subprocess
from pathlib import Path
from typing import Optional

def commit_and_push(
    message: str,
    branch: str,
    paths: list[str | Path],
    base_branch: Optional[str] = None,
    force: bool = False
) -> None:
    """Commit changes and push to specified branch.
    
    Args:
        message: Commit message
        branch: Branch to push to
        paths: List of paths to commit
        base_branch: Optional base branch to create new branch from
        force: If True, create fresh branch and force push (for generated content)
    """
    # Convert paths to strings
    path_strs = [str(p) for p in paths]
    
    # Set up git config
    subprocess.run(["git", "config", "--local", "user.email", "github-actions[bot]@users.noreply.github.com"])
    subprocess.run(["git", "config", "--local", "user.name", "github-actions[bot]"])
    
    if force:
        # Create fresh branch from base_branch or HEAD
        base = base_branch or "HEAD"
        logger.info(f"Creating fresh branch {branch} from {base}")
        subprocess.run(["git", "checkout", "-B", branch, base])
    else:
        # Normal branch handling
        if base_branch:
            logger.info(f"Creating new branch {branch} from {base_branch}")
            subprocess.run(["git", "checkout", "-b", branch, base_branch])
        else:
            logger.info(f"Switching to branch {branch}")
            subprocess.run(["git", "checkout", "-b", branch])
            subprocess.run(["git", "pull", "origin", branch], capture_output=True)
    
    # Stage and commit changes
    subprocess.run(["git", "add", *path_strs])
    
    # Only commit if there are changes
    result = subprocess.run(
        ["git", "diff", "--staged", "--quiet"],
        capture_output=True
    )
    if result.returncode == 1:  # Changes exist
        logger.info("Committing changes")
        subprocess.run(["git", "commit", "-m", message])
        
        # Push changes
        if force:
            logger.info(f"Force pushing {branch} branch")
            subprocess.run(["git", "push", "-f", "origin", branch])
        else:
            logger.info("Pushing changes")
            subprocess.run(["git", "push", "origin", branch])
    else:
        logger.info("No changes to commit")


"""CLI entry point for summary generator."""
import fire
from loguru import logger
from pathlib import Path
from . import generator
#from readme_generator.utils import commit_and_push
from . import special_summaries


def generate(root_dir: str = ".", push: bool = True) -> list[Path]:
    """Generate directory summaries and special summaries.
    
    Args:
        root_dir: Root directory to generate summaries for
        push: Whether to commit and push changes
        
    Returns:
        List of paths to generated summary files
    """
    logger.info(f"Generating summaries for {root_dir}")
    
    # Generate regular directory summaries
    gen = generator.SummaryGenerator(root_dir)
    summary_files = gen.generate_all_summaries()
    
    # Generate special summaries
    special_files = special_summaries.generate_special_summaries(root_dir)
    all_files = summary_files + special_files
    
    if push:
        logger.info("Committing and pushing changes")
        commit_and_push(
            message="Update directory summaries and special summaries",
            branch="summaries",
            paths=all_files,
            base_branch="main",
            force=True  # Use force push for generated content
        )
    
    return all_files

def main():
    """CLI entry point."""
    fire.Fire(generate)

if __name__ == "__main__":
    main()



================================================================================
File: src/scripts/generate_summaries/generator.py
================================================================================
"""Core summary generation functionality."""
from pathlib import Path
from typing import List, Set
from loguru import logger

class SummaryGenerator:
    """Generate summary files for each directory in the project."""
    
    def __init__(self, root_dir: str | Path):
        """Initialize generator with root directory.
        
        Args:
            root_dir: Root directory to generate summaries for
        """
        self.root_dir = Path(root_dir)
        
    def should_include_file(self, file_path: Path) -> bool:
        """Determine if a file should be included in the summary.
        
        Args:
            file_path: Path to file to check
            
        Returns:
            True if file should be included in summary
        """
        # Skip common files we don't want to summarize
        excluded_files = {
            '.git', '.gitignore', '.pytest_cache', '__pycache__',
            'SUMMARY', '.coverage', '.env', '.venv', '.idea', '.vscode'
        }
        
        # Skip excluded directories and files
        if any(part in excluded_files for part in file_path.parts):
            return False
            
        # Skip .github/workflows directory
        if '.github/workflows' in str(file_path):
            return False
            
        # Only include text files
        text_extensions = {'.py', '.md', '.txt', '.yml', '.yaml', '.toml', 
                         '.json', '.html', '.css', '.js', '.j2'}
        return file_path.suffix in text_extensions
    
    def should_include_directory(self, directory: Path) -> bool:
        """Determine if a directory should have a summary generated.
        
        Args:
            directory: Directory to check
            
        Returns:
            True if directory should have a summary
        """
        # Skip .github/workflows directory
        if '.github/workflows' in str(directory):
            return False
            
        # Skip other excluded directories
        excluded_dirs = {
            '.git', '__pycache__', '.pytest_cache',
            '.venv', '.idea', '.vscode'
        }
        
        return not any(part in excluded_dirs for part in directory.parts)
    
    def _collect_directories(self) -> Set[Path]:
        """Collect all directories containing files to summarize.
        
        Returns:
            Set of directory paths
        """
        directories = set()
        for file_path in self.root_dir.rglob('*'):
            if (file_path.is_file() and 
                self.should_include_file(file_path) and
                self.should_include_directory(file_path.parent)):
                directories.add(file_path.parent)
        return directories
        
    def generate_directory_summary(self, directory: Path) -> str:
        """Generate a summary for a single directory.
        
        Args:
            directory: Directory to generate summary for
            
        Returns:
            Generated summary text
        """
        logger.debug(f"Generating summary for {directory}")
        summary = []
        
        # Process all files in the directory
        for file_path in sorted(directory.rglob('*')):
            if not file_path.is_file() or not self.should_include_file(file_path):
                continue
                
            try:
                # Get relative path from root for the header
                rel_path = file_path.relative_to(self.root_dir)
                
                # Read file content
                content = file_path.read_text(encoding='utf-8')
                
                # Add to summary with clear separation
                summary.extend([
                    '=' * 80,
                    f'File: {rel_path}',
                    '=' * 80,
                    content,
                    '\n'  # Extra newline for separation
                ])
            except Exception as e:
                logger.error(f"Error processing {file_path}: {e}")
                
        return '\n'.join(summary)
        
    def generate_all_summaries(self) -> List[Path]:
        """Generate summary files for all directories.
        
        Returns:
            List of paths to generated summary files
        """
        logger.info("Starting summary generation")
        summary_files = []
        
        # Collect directories
        directories = self._collect_directories()
        logger.info(f"Found {len(directories)} directories to process")
        
        # Generate summaries
        for directory in sorted(directories):
            if not self.should_include_directory(directory):
                continue
                
            summary_content = self.generate_directory_summary(directory)
            summary_path = directory / 'SUMMARY'
            
            try:
                summary_path.write_text(summary_content, encoding='utf-8')
                logger.info(f"Generated summary for {directory}")
                summary_files.append(summary_path)
            except Exception as e:
                logger.error(f"Error writing summary for {directory}: {e}")
                
        return summary_files



================================================================================
File: src/scripts/generate_summaries/signature_extractor.py
================================================================================
# signature_extractor.py
"""Extracts and formats Python code signatures with proper nesting."""
import ast
from dataclasses import dataclass
from pathlib import Path
from typing import List, Dict
from loguru import logger

@dataclass
class Signature:
    """Represents a Python function or class signature with documentation."""
    name: str
    kind: str  # 'function', 'method', or 'class'
    args: list[str]
    returns: str | None
    docstring: str | None
    decorators: list[str]
    methods: list['Signature']  # For storing class methods

class ParentNodeTransformer(ast.NodeTransformer):
    """Add parent references to all nodes in the AST."""
    
    def visit(self, node: ast.AST) -> ast.AST:
        """Visit a node and add parent references to all its children."""
        for child in ast.iter_child_nodes(node):
            child.parent = node
        return super().visit(node)

class SignatureExtractor:
    """Extracts detailed signatures from Python files."""
    
    def get_type_annotation(self, node: ast.AST) -> str:
        """Convert AST annotation node to string representation."""
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Constant):
            return repr(node.value)
        elif isinstance(node, ast.Subscript):
            container = self.get_type_annotation(node.value)
            params = self.get_type_annotation(node.slice)
            return f"{container}[{params}]"
        elif isinstance(node, ast.BinOp):
            left = self.get_type_annotation(node.left)
            right = self.get_type_annotation(node.right)
            return f"{left} | {right}"
        elif isinstance(node, ast.Tuple):
            elts = [self.get_type_annotation(e) for e in node.elts]
            return f"[{', '.join(elts)}]"
        return "Any"
    
    def get_arg_string(self, arg: ast.arg) -> str:
        """Convert function argument to string with type annotation."""
        arg_str = arg.arg
        if arg.annotation:
            type_str = self.get_type_annotation(arg.annotation)
            arg_str += f": {type_str}"
        return arg_str

    def extract_signatures(self, source: str) -> List[Signature]:
        """Extract all function and class signatures from source code."""
        try:
            # Parse and add parent references
            tree = ast.parse(source)
            transformer = ParentNodeTransformer()
            transformer.visit(tree)
            
            signatures: List[Signature] = []
            classes: Dict[ast.ClassDef, Signature] = {}
            
            for node in ast.walk(tree):
                # Handle functions
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    args = []
                    for arg in node.args.args:
                        args.append(self.get_arg_string(arg))
                    
                    returns = None
                    if node.returns:
                        returns = self.get_type_annotation(node.returns)
                    
                    decorators = []
                    for decorator in node.decorator_list:
                        if isinstance(decorator, ast.Name):
                            decorators.append(f"@{decorator.id}")
                        elif isinstance(decorator, ast.Call):
                            if isinstance(decorator.func, ast.Name):
                                decorators.append(f"@{decorator.func.id}(...)")
                    
                    sig = Signature(
                        name=node.name,
                        kind='method' if hasattr(node, 'parent') and isinstance(node.parent, ast.ClassDef) else 'function',
                        args=args,
                        returns=returns,
                        docstring=ast.get_docstring(node),
                        decorators=decorators,
                        methods=[]
                    )
                    
                    # Add to appropriate parent
                    if hasattr(node, 'parent') and isinstance(node.parent, ast.ClassDef) and node.parent in classes:
                        classes[node.parent].methods.append(sig)
                    else:
                        signatures.append(sig)
                
                # Handle classes
                elif isinstance(node, ast.ClassDef):
                    bases = []
                    for base in node.bases:
                        if isinstance(base, ast.Name):
                            bases.append(base.id)
                    
                    decorators = []
                    for decorator in node.decorator_list:
                        if isinstance(decorator, ast.Name):
                            decorators.append(f"@{decorator.id}")
                    
                    class_sig = Signature(
                        name=node.name,
                        kind='class',
                        args=bases,
                        returns=None,
                        docstring=ast.get_docstring(node),
                        decorators=decorators,
                        methods=[]
                    )
                    
                    classes[node] = class_sig
                    signatures.append(class_sig)
                    
            return signatures
        except Exception as e:
            logger.error(f"Error parsing source: {e}")
            return []

    def format_signature(self, sig: Signature, indent: int = 0) -> List[str]:
        """Format a signature for display with proper indentation."""
        lines = []
        indent_str = "    " * indent
        
        # Add decorators
        for decorator in sig.decorators:
            lines.append(f"{indent_str}{decorator}")
        
        # Format the signature line
        if sig.kind == 'class':
            base_str = f"({', '.join(sig.args)})" if sig.args else ""
            lines.append(f"{indent_str}class {sig.name}{base_str}")
        else:
            async_prefix = "async " if "async" in sig.decorators else ""
            args_str = ", ".join(sig.args)
            return_str = f" -> {sig.returns}" if sig.returns else ""
            lines.append(f"{indent_str}{async_prefix}def {sig.name}({args_str}){return_str}")
        
        # Add docstring if present
        if sig.docstring:
            doc_lines = sig.docstring.split('\n')
            if len(doc_lines) == 1:
                lines.append(f'{indent_str}    """{sig.docstring}"""')
            else:
                lines.append(f'{indent_str}    """')
                for doc_line in doc_lines:
                    if doc_line.strip():
                        lines.append(f"{indent_str}    {doc_line}")
                lines.append(f'{indent_str}    """')
        
        # Add methods for classes
        if sig.methods:
            lines.append("")  # Add spacing
            for method in sig.methods:
                lines.extend(self.format_signature(method, indent + 1))
                lines.append("")  # Add spacing between methods
        
        return lines

def generate_python_summary(root_dir: str | Path) -> str:
    """Generate enhanced Python project structure summary.
    
    Args:
        root_dir: Root directory of the project
        
    Returns:
        Formatted markdown string of Python signatures
    """
    root_dir = Path(root_dir)
    extractor = SignatureExtractor()
    content = ["# Python Project Structure\n"]
    
    for file in sorted(root_dir.rglob("*.py")):
        if any(part.startswith('.') for part in file.parts):
            continue
        if '__pycache__' in file.parts:
            continue
            
        try:
            # Get relative path
            rel_path = file.relative_to(root_dir)
            
            # Read and extract signatures
            source = file.read_text()
            signatures = extractor.extract_signatures(source)
            
            # Only include files that have actual content
            if signatures:
                content.append(f"## {rel_path}")
                content.append("```python")
                
                # Format each signature
                for sig in signatures:
                    content.extend(extractor.format_signature(sig))
                    content.append("")  # Add spacing between top-level items
                
                content.append("```\n")
            
        except Exception as e:
            logger.error(f"Error processing {file}: {e}")
    
    return "\n".join(content)



================================================================================
File: src/scripts/generate_summaries/special_summaries.py
================================================================================
"""Special summary generators for project-wide summaries."""
from pathlib import Path
from typing import List
from loguru import logger
from .signature_extractor import SignatureExtractor, generate_python_summary  # New import

class SpecialSummariesGenerator:
    """Generate special project-wide summary files."""
    
    def __init__(self, root_dir: str | Path):
        """Initialize generator with root directory."""
        self.root_dir = Path(root_dir)
        self.summaries_dir = self.root_dir / "SUMMARIES"
        self.signature_extractor = SignatureExtractor()  # New instance
    
    def _find_readmes(self, include_root: bool = True) -> List[Path]:
        """Find all README files in the project."""
        readmes = []
        for file in self.root_dir.rglob("README.md"):
            if not include_root and file.parent == self.root_dir:
                continue
            readmes.append(file)
        return sorted(readmes)
    
    def generate_special_summaries(self) -> List[Path]:
        """Generate all special summary files.
        
        Returns:
            List of paths to generated summary files
        """
        self.summaries_dir.mkdir(exist_ok=True)
        generated_files = []
        
        # Generate READMEs.md
        readmes_path = self.summaries_dir / "READMEs.md"
        readme_content = []
        for readme in self._find_readmes(include_root=True):
            rel_path = readme.relative_to(self.root_dir)
            readme_content.extend([
                "=" * 80,
                f"# {rel_path}",
                "=" * 80,
                readme.read_text(),
                "\n"
            ])
        readmes_path.write_text("\n".join(readme_content))
        generated_files.append(readmes_path)
        
        # Generate README_SUBs.md
        subs_path = self.summaries_dir / "README_SUBs.md"
        subs_content = []
        for readme in self._find_readmes(include_root=False):
            rel_path = readme.relative_to(self.root_dir)
            subs_content.extend([
                "=" * 80,
                f"# {rel_path}",
                "=" * 80,
                readme.read_text(),
                "\n"
            ])
        subs_path.write_text("\n".join(subs_content))
        generated_files.append(subs_path)
        
        # Generate enhanced PYTHON.md
        python_path = self.summaries_dir / "PYTHON.md"
        python_content = generate_python_summary(self.root_dir)  # Using new generator
        python_path.write_text(python_content)
        generated_files.append(python_path)
        
        return generated_files

def generate_special_summaries(root_dir: str | Path = ".") -> List[Path]:
    """Generate special summaries for the project."""
    generator = SpecialSummariesGenerator(root_dir)
    return generator.generate_special_summaries()



================================================================================
File: src/scripts/readme_generator.py
================================================================================
from pathlib import Path
from typing import List
from loguru import logger
from jinja2 import Environment, FileSystemLoader
from .utils import load_config, get_project_root, commit_and_push

def get_section_templates(template_dir: Path) -> List[str]:
    """Get all section templates in proper order.
    
    Args:
        template_dir: Path to template directory containing sections/
        
    Returns:
        List of template names in desired order
    """
    # Define section order
    section_order = {
        "introduction.md.j2": 0,
        "prerequisites.md.j2": 1,
        "usage.md.j2": 2,
        "development.md.j2": 3,
        "summaries.md.j2": 4,
        "site.md.j2": 5,
        "structure.md.j2": 6,
        "todo.md.j2": 999  # Always last if present
    }
    
    sections_dir = template_dir / "sections"
    templates = []
    
    # Collect all template files
    for file in sections_dir.glob("*.md.j2"):
        # Skip todo if it doesn't exist (it's optional)
        if file.name == "todo.md.j2" and not file.exists():
            continue
        templates.append(file.name)
    
    # Sort by explicit order, then alphabetically for any new sections
    return sorted(
        templates,
        key=lambda x: section_order.get(x, 500)
    )

def generate_readme() -> None:
    """Generate README from templates and commit changes"""
    project_root = get_project_root()
    logger.debug(f"Project root identified as: {project_root}")
    
    logger.info("Loading configurations")
    project_config = load_config("pyproject.toml")
    
    logger.info("Setting up Jinja2 environment")
    template_dir = project_root / 'docs/readme'
    logger.debug(f"Template directory: {template_dir}")
    
    env = Environment(
        loader=FileSystemLoader(template_dir),
        trim_blocks=True,
        lstrip_blocks=True
    )
    
    # Add template utility functions
    env.globals['get_section_templates'] = lambda: get_section_templates(template_dir)
    
    template = env.get_template('base.md.j2')
    
    variables = {
        'project': project_config['project'],
        'readme': project_config['tool']['readme'],
    }
    
    logger.info("Rendering README template")
    output = template.render(**variables)
    
    readme_path = project_root / 'README.llm'
    logger.debug(f"Writing README to: {readme_path}")
    readme_path.write_text(output)
    
    logger.info("Committing changes")
    commit_and_push(readme_path)

if __name__ == "__main__":
    generate_readme()



================================================================================
File: src/scripts/registry/__init__.py
================================================================================
# scripts/registry/__init__.py
"""ML Training Recommendations Registry.

A system for tracking, managing, and organizing machine learning training recommendations
from research papers with unique identifiers and status tracking.
"""

from .types import MLRStatus, Recommendation, Source, Evidence
from .identifiers import MLRIdentifierRegistry
from .recommendations import RecommendationRegistry, build_registry_from_yaml
from .io import (
    load_research_yaml,
    save_registry,
    load_registry,
    registry_to_markdown,
    RegistryDataError
)

__version__ = "0.1.0"

__all__ = [
    'MLRStatus',
    'Recommendation',
    'Source',
    'Evidence',
    'MLRIdentifierRegistry',
    'RecommendationRegistry',
    'build_registry_from_yaml',
    'load_research_yaml',
    'save_registry',
    'load_registry',
    'registry_to_markdown',
    'RegistryDataError',
]



================================================================================
File: src/scripts/registry/cli.py
================================================================================
# src/scripts/registry/cli.py
"""Command-line interface for registry operations."""

import fire
from pathlib import Path
from loguru import logger
from typing import Optional
from . import (
    build_registry_from_yaml,
    load_research_yaml, 
    save_registry,
    registry_to_markdown
)
#from ..utils import commit_and_push
from llamero.utils import commit_and_push_to_branch #commit_and_push

def build(
    input_path: str | Path = "data/research.yaml",
    output_dir: str | Path = "data",
    push: bool = True,
    branch: Optional[str] = "HEAD"
) -> None:
    """Build registry from research YAML and generate outputs.
    
    Args:
        input_path: Path to research YAML file
        output_dir: Directory to save outputs (default: data directory)
        push: Whether to commit and push changes
        branch: Optional branch name to commit to (default: current branch)
    """
    logger.info(f"Building registry from {input_path}")
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Generate registry
    yaml_data = load_research_yaml(input_path)
    registry = build_registry_from_yaml(yaml_data)
    
    # Save outputs
    registry_yaml = output_dir / "registry.yaml"
    registry_md = output_dir / "REGISTRY.md"
    
    save_registry(registry, registry_yaml)
    registry_to_markdown(registry, registry_md)
    logger.info(f"Registry outputs saved to {output_dir}")

    rdme= output_dir.parent / "docs/readme/sections/registry.md.j2"
    registry_to_markdown(registry, rdme)
    
    
    if push:
        logger.info("Committing changes")
        #commit_and_push([registry_yaml, registry_md, rdme])
        commit_and_push_to_branch(
            message="Update ML training registry",
            branch=branch or "main",
            paths=[registry_yaml, registry_md, rdme],
            force=False
        )


def cli():
    """CLI entry point."""
    return fire.Fire({
        'build': build
    })


if __name__ == "__main__":
    cli()



================================================================================
File: src/scripts/registry/identifiers.py
================================================================================
# scripts/registry/identifiers.py
"""MLR identifier generation and management."""

import json
import os
import re
from collections import defaultdict
from pathlib import Path
from typing import Dict, Optional
import logging

logger = logging.getLogger(__name__)

class MLRIdentifierRegistry:
    """Manages unique identifiers for ML recommendations."""
    
    def __init__(self, registry_file: str | Path = "mlr_registry.json"):
        """Initialize the identifier registry.
        
        Args:
            registry_file: Path to the JSON file storing ID mappings
        """
        self.registry_file = Path(registry_file)
        self.current_ids = self._load_registry()
        self.author_counters = self._initialize_author_counters()
        
    def _load_registry(self) -> Dict[str, Dict]:
        """Load existing MLR IDs from registry file."""
        try:
            if self.registry_file.exists():
                with open(self.registry_file, 'r') as f:
                    return json.load(f)
            logger.info(f"No existing registry found at {self.registry_file}")
        except json.JSONDecodeError:
            logger.warning(f"Error reading registry file {self.registry_file}. Starting fresh.")
        return {'paper_ids': {}, 'recommendation_ids': {}}
    
    def _initialize_author_counters(self) -> Dict[str, int]:
        """Initialize counters for author IDs from existing registry."""
        counters = defaultdict(int)
        for paper_id in self.current_ids['paper_ids'].values():
            if match := re.match(r'([A-Za-z]+)(\d+)', paper_id):
                author, num = match.groups()
                counters[author] = max(counters[author], int(num))
        return counters
    
    def _save_registry(self) -> None:
        """Save current MLR IDs to registry file."""
        self.registry_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self.registry_file, 'w') as f:
            json.dump(self.current_ids, f, indent=2)
        logger.debug(f"Saved registry to {self.registry_file}")
    
    def get_paper_id(self, first_author: str, year: int, arxiv_id: Optional[str] = None) -> str:
        """Get or generate a paper identifier.
        
        Args:
            first_author: First author's name
            year: Publication year
            arxiv_id: Optional arXiv identifier
            
        Returns:
            Unique paper identifier string
        """
        paper_key = f"{first_author}-{year}-{arxiv_id if arxiv_id else 'none'}"
        
        if paper_key in self.current_ids['paper_ids']:
            return self.current_ids['paper_ids'][paper_key]
        
        author_base = re.sub(r'[^A-Za-z]', '', first_author)
        self.author_counters[author_base] += 1
        paper_id = f"{author_base}{self.author_counters[author_base]:03d}"
        
        self.current_ids['paper_ids'][paper_key] = paper_id
        self._save_registry()
        logger.debug(f"Generated new paper ID {paper_id} for {paper_key}")
        
        return paper_id
            
    def generate_id(self, year: int, paper_id: str) -> str:
        """Generate a new unique MLR identifier.
        
        Args:
            year: Publication year
            paper_id: Unique paper identifier
            
        Returns:
            MLR identifier string
        """
        key = f"{year}-{paper_id}"
        if key not in self.current_ids['recommendation_ids']:
            self.current_ids['recommendation_ids'][key] = 0
        
        self.current_ids['recommendation_ids'][key] += 1
        mlr_id = f"MLR-{year}-{paper_id}-{self.current_ids['recommendation_ids'][key]:04d}"
        self._save_registry()
        logger.debug(f"Generated new MLR ID {mlr_id}")
        return mlr_id



================================================================================
File: src/scripts/registry/io.py
================================================================================
# src/scripts/registry/io.py
"""I/O operations for the ML recommendation registry."""

import yaml
import json
from pathlib import Path
from typing import Dict, Union
from loguru import logger
from datetime import datetime
from collections import defaultdict

from .recommendations import RecommendationRegistry
from .types import MLRStatus

class RegistryDataError(Exception):
    """Raised when there are issues with registry data format."""
    pass

def validate_paper_entry(paper: Dict, year: str) -> None:
    """Validate a single paper entry.
    
    Args:
        paper: Dictionary containing paper data
        year: Year the paper is from (for error messages)
        
    Raises:
        RegistryDataError: If paper data is invalid
    """
    required_fields = {
        'title': str,
        'first_author': str,
        'year': int,
        #'topics': list
    }

    # Check for missing required fields
    missing_fields = [field for field in required_fields if field not in paper]
    if missing_fields:
        logger.warning(paper)
        raise RegistryDataError(
            f"Paper in year {year} missing required fields: {', '.join(missing_fields)}"
        )

    # Check field types
    # for field, expected_type in required_fields.items():
    #     if not isinstance(paper[field], expected_type):
    #         logger.warning(paper)
    #         raise RegistryDataError(
    #             f"Paper in year {year} has invalid type for {field}: "
    #             f"expected {expected_type.__name__}, got {type(paper[field]).__name__}"
    #         )

    # # Validate year matches container
    # if str(paper['year']) != str(year):
    #     raise RegistryDataError(
    #         f"Paper year {paper['year']} doesn't match container year {year}"
    #     )

    # # Validate topics not empty
    # if not paper['topics']:
    #     raise RegistryDataError(
    #         f"Paper '{paper['title']}' ({year}) has empty topics list"
    #     )

    # Validate topics are strings
    # if not all(isinstance(topic, str) for topic in paper['topics']):
    #     raise RegistryDataError(
    #         f"Paper '{paper['title']}' ({year}) has non-string topics"
    #     )

    # # If SOTA recommendations present, validate they're strings
    # if 'sota' in paper and not all(isinstance(rec, str) for rec in paper['sota']):
    #     raise RegistryDataError(
    #         f"Paper '{paper['title']}' ({year}) has non-string SOTA recommendations"
    #     )

def load_research_yaml(file_path: Union[str, Path]) -> Dict:
    """Load research data from YAML file.
    
    Args:
        file_path: Path to the YAML file
        
    Returns:
        Dictionary containing the research data
        
    Raises:
        FileNotFoundError: If the file doesn't exist
        yaml.YAMLError: If the file contains invalid YAML
        RegistryDataError: If the data format is invalid
    """
    file_path = Path(file_path)
    if not file_path.exists():
        raise FileNotFoundError(f"Research data file not found: {file_path}")

    try:
        with open(file_path, 'r') as f:
            data = yaml.safe_load(f)
    except yaml.YAMLError as e:
        logger.error(f"Error parsing YAML file {file_path}: {e}")
        raise

    # Validate basic data structure
    if not isinstance(data, dict):
        raise RegistryDataError("Research data must be a dictionary")

    # Validate years and entries
    for year, papers in data.items():
        try:
            year_int = int(year)
            if not 1900 <= year_int <= datetime.now().year:
                raise RegistryDataError(f"Invalid year: {year}")
        except ValueError:
            raise RegistryDataError(f"Invalid year format: {year}")

        if not isinstance(papers, list):
            raise RegistryDataError(f"Papers for year {year} must be a list")

        # Validate each paper
        for paper in papers:
            if not isinstance(paper, dict):
                raise RegistryDataError(f"Invalid paper entry in year {year}")
            validate_paper_entry(paper, year)

    return data

def save_registry(registry: RecommendationRegistry, output_file: Union[str, Path]) -> None:
    """Save registry to a file.
    
    Args:
        registry: RecommendationRegistry instance
        output_file: Path where to save the file
    """
    output_file = Path(output_file)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    data = registry.export_registry()
    
    try:
        # Write as JSONL if .jsonl extension
        if output_file.suffix == '.jsonl':
            with open(output_file, 'w') as f:
                for rec in data['recommendations']:
                    f.write(json.dumps(rec) + '\n')
        # Write as YAML for other extensions
        else:
            with open(output_file, 'w') as f:
                yaml.safe_dump(
                    data,
                    f,
                    sort_keys=False,
                    allow_unicode=True,
                    default_flow_style=False
                )
        logger.info(f"Registry saved to {output_file}")
    except Exception as e:
        logger.error(f"Error saving registry to {output_file}: {e}")
        raise

def load_registry(file_path: Union[str, Path]) -> Dict:
    """Load a saved registry file.
    
    Args:
        file_path: Path to the registry file
        
    Returns:
        Dictionary containing the registry data
    """
    file_path = Path(file_path)
    if not file_path.exists():
        raise FileNotFoundError(f"Registry file not found: {file_path}")
    
    try:
        # Handle JSONL format
        if file_path.suffix == '.jsonl':
            recommendations = []
            with open(file_path, 'r') as f:
                for line in f:
                    if line.strip():
                        recommendations.append(json.loads(line))
            data = {
                'metadata': {
                    'schema_version': '1.0',
                    'last_updated': datetime.now().strftime('%Y-%m-%d')
                },
                'recommendations': recommendations
            }
        # Handle YAML format
        else:
            with open(file_path, 'r') as f:
                data = yaml.safe_load(f)
    except (yaml.YAMLError, json.JSONDecodeError) as e:
        logger.error(f"Error parsing registry file {file_path}: {e}")
        raise
    
    # Basic validation
    if not isinstance(data, dict):
        raise RegistryDataError("Invalid registry format")
    
    if 'recommendations' not in data:
        raise RegistryDataError("Registry missing recommendations")
    
    if not isinstance(data['recommendations'], list):
        raise RegistryDataError("Recommendations must be a list")
        
    return data

def registry_to_markdown(registry: RecommendationRegistry, output_file: Union[str, Path]) -> None:
    """Export registry to a markdown document."""
    output_file = Path(output_file)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    data = registry.export_registry()
    
    with open(output_file, 'w') as f:
        f.write("# ML Training Recommendations Registry\n\n")
        f.write(f"Last updated: {data['metadata']['last_updated']}\n\n")
        
        # Group recommendations by status and topic for display
        status_topics = defaultdict(lambda: defaultdict(list))
        for rec in data['recommendations']:
            status = rec.get('status', 'standard')
            topic = rec.get('topic', 'uncategorized')
            status_topics[status][topic].append(rec)
        
        # Write recommendations by status and topic
        for status in MLRStatus:
            f.write(f"## {status.value.title()} Recommendations\n\n")
            
            for topic, recs in sorted(status_topics[status.value].items()):
                if recs:
                    f.write(f"### {topic}\n\n")
                    for rec in recs:
                        f.write(f"- {rec['recommendation']}\n")
                        if rec.get('implementations'):
                            f.write(f"  - Implementations: {', '.join(rec['implementations'])}\n")
                        f.write("\n")
            f.write("\n")
        
        # Write statistics
        f.write("## Statistics\n\n")
        for topic_data in data['topics'].items():
            topic, stats = topic_data
            f.write(f"### {topic}\n\n")
            f.write(f"- Total recommendations: {stats['count']}\n")
            if stats['years']['earliest'] and stats['years']['latest']:
                f.write(f"- Year range: {stats['years']['earliest']} - {stats['years']['latest']}\n")
            f.write("\n")



================================================================================
File: src/scripts/registry/recommendations.py
================================================================================
# src/scripts/registry/recommendations.py
"""Core recommendation registry functionality."""
from collections import defaultdict
from datetime import datetime
from typing import Dict, List, Optional, Set
import logging
from omegaconf import OmegaConf, DictConfig

from .types import MLRStatus, Recommendation, Source, Evidence, create_config_from_dict
from .identifiers import MLRIdentifierRegistry

logger = logging.getLogger(__name__)

def generate_topic_id(topic: str, recommendation: str) -> str:
    """Generate a unique topic-based ID for a recommendation."""
    import re
    words = recommendation.lower().split()[:5]
    slug = '-'.join(words)
    slug = re.sub(r'[^a-z0-9-]', '', slug)
    return f"{topic.lower().replace(' ', '-')}/{slug}"

class RecommendationRegistry:
    """Registry for ML training recommendations."""
    
    def __init__(self, id_registry: Optional[MLRIdentifierRegistry] = None):
        """Initialize the recommendation registry."""
        self.recommendations: Dict[str, Recommendation] = {}
        self.topic_to_recommendations: Dict[str, List[str]] = defaultdict(list)
        self.id_registry = id_registry or MLRIdentifierRegistry()
        self._config = create_config_from_dict({
            'recommendations': {},
            'metadata': {
                'schema_version': '1.0',
                'last_updated': datetime.now().strftime('%Y-%m-%d')
            }
        })
        logger.info("Initialized recommendation registry")

    def add_recommendation(self, 
                         topic: str,
                         recommendation: str,
                         first_author: str,
                         source_paper: str,
                         year: int,
                         arxiv_id: Optional[str] = None,
                         experimental: bool = False,
                         superseded_by: Optional[str] = None,
                         implementations: Optional[List[str]] = None) -> str:
        """Add a recommendation to the registry."""
        topic_id = generate_topic_id(topic, recommendation)
        paper_id = self.id_registry.get_paper_id(first_author, year, arxiv_id)
        mlr_id = self.id_registry.generate_id(year, paper_id)
        
        source = Source(
            paper=source_paper,
            paper_id=paper_id,
            year=year,
            first_author=first_author,
            arxiv_id=arxiv_id
        )
        
        # Determine status
        if superseded_by:
            status = MLRStatus.DEPRECATED
        elif experimental:
            status = MLRStatus.EXPERIMENTAL
        else:
            status = MLRStatus.STANDARD
            
        rec = Recommendation.create(
            id=mlr_id,
            recommendation=recommendation,
            topic=topic,
            topic_id=topic_id,
            source=source,
            status=status,
            superseded_by=superseded_by,
            deprecated_date=datetime.now().strftime('%Y-%m-%d') if superseded_by else None,
            implementations=implementations or []
        )
        
        self.recommendations[mlr_id] = rec
        self.topic_to_recommendations[topic].append(mlr_id)
        
        logger.info(f"Added recommendation {mlr_id} with status {status}")
        return mlr_id

    def get_recommendation_by_mlr(self, mlr_id: str) -> Optional[Recommendation]:
        """Get a recommendation by its MLR ID."""
        return self.recommendations.get(mlr_id)
    
    def get_recommendations_by_status(self, status: MLRStatus) -> List[Recommendation]:
        """Get all recommendations with a given status."""
        return [rec for rec in self.recommendations.values() if rec.status == status]
    
    def get_recommendations_by_topic(self, topic: str, status: Optional[MLRStatus] = None) -> List[Recommendation]:
        """Get recommendations for a topic, optionally filtered by status."""
        recs = [self.recommendations[mlr_id] for mlr_id in self.topic_to_recommendations[topic]]
        if status:
            recs = [rec for rec in recs if rec.status == status]
        return sorted(recs, key=lambda x: x.source.year)

    def get_topics(self) -> Set[str]:
        """Get all unique topics in the registry."""
        return set(self.topic_to_recommendations.keys())

    def export_registry(self) -> Dict:
        """Export the registry as a list of atomic recommendations."""
        return {
            'metadata': {
                'last_updated': datetime.now().strftime('%Y-%m-%d'),
                'schema_version': '1.0',
                'status_types': [status.value for status in MLRStatus]
            },
            'recommendations': [
                rec.to_dict() for rec in self.recommendations.values()
            ],
            # Include topic stats for informational purposes
            'topics': {
                topic: {
                    'count': len(recs),
                    'years': {
                        'earliest': min(self.recommendations[rid].source.year for rid in recs),
                        'latest': max(self.recommendations[rid].source.year for rid in recs)
                    }
                }
                for topic, recs in self.topic_to_recommendations.items()
            }
        }

def build_registry_from_yaml(yaml_data: Dict) -> RecommendationRegistry:
    """Build a recommendation registry from YAML research data."""
    registry = RecommendationRegistry()
    config = create_config_from_dict(yaml_data)
    
    # Process each year's papers
    for year, papers in config.items():
        for paper in papers:
            # Extract basic paper info
            first_author = paper.first_author
            arxiv_id = paper.get('arxiv_id', None)
            paper_id = f"{first_author} et al. ({year})"
            
            # Process SOTA recommendations
            if hasattr(paper, 'sota') and paper.sota:
                for rec in paper.sota:
                    main_topic = paper.topics[0] if paper.topics else 'general'
                    mlr_id = registry.add_recommendation(
                        topic=main_topic,
                        recommendation=rec,
                        first_author=first_author,
                        source_paper=paper_id,
                        year=int(year),
                        arxiv_id=arxiv_id,
                        implementations=paper.get('models', [])
                    )
                    logger.info(f"Added recommendation {mlr_id}: {rec}")
            
            # Process experimental recommendations
            if paper.get('experimental', False):
                for rec in paper.get('sota', []):
                    mlr_id = registry.add_recommendation(
                        topic=paper.topics[0],
                        recommendation=rec,
                        first_author=first_author,
                        source_paper=paper_id,
                        year=int(year),
                        arxiv_id=arxiv_id,
                        experimental=True
                    )
                    logger.info(f"Added experimental recommendation {mlr_id}: {rec}")
            
            # Process deprecated/superseded recommendations
            if 'attic' in paper and 'superseded_by' in paper.attic:
                for rec in paper.get('sota', []):
                    mlr_id = registry.add_recommendation(
                        topic=paper.topics[0],
                        recommendation=rec,
                        first_author=first_author,
                        source_paper=paper_id,
                        year=int(year),
                        arxiv_id=arxiv_id,
                        superseded_by=paper.attic.superseded_by
                    )
                    logger.info(f"Added deprecated recommendation {mlr_id}: {rec}")

    return registry



================================================================================
File: src/scripts/registry/types.py
================================================================================
# scripts/registry/types.py
"""Type definitions for ML recommendation registry."""

from enum import Enum
from typing import Dict, List, Optional, Union
from dataclasses import dataclass, field
from datetime import datetime
from omegaconf import OmegaConf, DictConfig, MISSING

class MLRStatus(str, Enum):
    """Status states for ML recommendations."""
    EXPERIMENTAL = "experimental"
    STANDARD = "standard"
    DEPRECATED = "deprecated"

@dataclass
class Source:
    """Source information for a recommendation."""
    paper: str = MISSING
    paper_id: str = MISSING
    year: int = MISSING
    first_author: str = MISSING
    arxiv_id: Optional[str] = None

    @classmethod
    def from_dict(cls, data: Union[Dict, DictConfig]) -> 'Source':
        """Create Source from dictionary or DictConfig."""
        conf = OmegaConf.create(data)
        return cls(
            paper=conf.paper,
            paper_id=conf.paper_id,
            year=conf.year,
            first_author=conf.first_author,
            arxiv_id=conf.get('arxiv_id', None)
        )

    def to_dict(self) -> Dict:
        """Convert to dictionary, omitting None values."""
        return {k: v for k, v in OmegaConf.to_container(OmegaConf.create(self)).items() if v is not None}

@dataclass
class Evidence:
    """Supporting evidence for a recommendation."""
    paper: str = MISSING
    paper_id: str = MISSING
    year: int = MISSING
    arxiv_id: Optional[str] = None

    @classmethod
    def from_dict(cls, data: Union[Dict, DictConfig]) -> 'Evidence':
        """Create Evidence from dictionary or DictConfig."""
        conf = OmegaConf.create(data)
        return cls(
            paper=conf.paper,
            paper_id=conf.paper_id,
            year=conf.year,
            arxiv_id=conf.get('arxiv_id', None)
        )

    def to_dict(self) -> Dict:
        """Convert to dictionary, omitting None values."""
        return {k: v for k, v in OmegaConf.to_container(OmegaConf.create(self)).items() if v is not None}

@dataclass
class Recommendation:
    """ML training recommendation."""
    id: str = MISSING
    recommendation: str = MISSING
    topic: str = MISSING
    topic_id: str = MISSING
    source: Source = MISSING
    status: MLRStatus = MISSING
    supporting_evidence: List[Evidence] = field(default_factory=list)
    superseded_by: Optional[str] = None
    deprecated_date: Optional[str] = None
    implementations: List[str] = field(default_factory=list)

    @classmethod
    def create(cls, 
               id: str,
               recommendation: str,
               topic: str,
               topic_id: str,
               source: Union[Dict, DictConfig, Source],
               status: MLRStatus,
               **kwargs) -> 'Recommendation':
        """Create a recommendation from raw data."""
        if isinstance(source, (Dict, DictConfig)):
            source = Source.from_dict(source)
        
        evidence_list = kwargs.get('supporting_evidence', [])
        if evidence_list:
            evidence_list = [
                Evidence.from_dict(e) if isinstance(e, (Dict, DictConfig)) else e
                for e in evidence_list
            ]
        
        return cls(
            id=id,
            recommendation=recommendation,
            topic=topic,
            topic_id=topic_id,
            source=source,
            status=status,
            supporting_evidence=evidence_list,
            superseded_by=kwargs.get('superseded_by'),
            deprecated_date=kwargs.get('deprecated_date'),
            implementations=kwargs.get('implementations', [])
        )

    def to_dict(self) -> Dict:
        """Convert recommendation to dictionary."""
        conf = OmegaConf.create({
            'id': self.id,
            'recommendation': self.recommendation,
            'topic': self.topic,
            'topic_id': self.topic_id,
            'source': self.source.to_dict(),
            'status': self.status.value,
            'supporting_evidence': [e.to_dict() for e in self.supporting_evidence],
            'implementations': self.implementations,
            'superseded_by': self.superseded_by,
            'deprecated_date': self.deprecated_date
        })
        return {k: v for k, v in OmegaConf.to_container(conf).items() if v is not None}

def create_config_from_dict(data: Dict) -> DictConfig:
    """Create an OmegaConf config from a dictionary."""
    return OmegaConf.create(data)



================================================================================
File: src/scripts/utils.py
================================================================================
from pathlib import Path
import tomli
import os
import subprocess
from loguru import logger


def get_project_root() -> Path:
    """
    Get the project root directory by looking for pyproject.toml
    Returns the absolute path to the project root
    """
    current = Path.cwd().absolute()
    
    # Look for pyproject.toml in current and parent directories
    while current != current.parent:
        if (current / 'pyproject.toml').exists():
            return current
        current = current.parent
    
    # If we couldn't find it, use the current working directory
    # and log a warning
    logger.warning("Could not find pyproject.toml in parent directories")
    return Path.cwd().absolute()

def load_config(config_path: str) -> dict:
    """
    Load configuration from a TOML file
    
    Args:
        config_path (str): Path to the TOML configuration file relative to project root
        
    Returns:
        dict: Parsed configuration data
    """
    try:
        full_path = get_project_root() / config_path
        logger.debug(f"Attempting to load config from: {full_path}")
        with open(full_path, "rb") as f:
            return tomli.load(f)
    except FileNotFoundError:
        logger.error(f"Configuration file not found: {full_path}")
        raise

def commit_and_push(
    paths: str | Path | list[str | Path],
    message: str|None = None,
    branch: str|None = None,
    base_branch: str|None = None,
    force: bool = False
) -> None:
    """Commit changes and push to specified or current branch.
    
    Args:
        paths: Path or list of paths to commit
        message: Commit message (defaults to "Update files via automated commit")
        branch: Branch to push to (defaults to current branch)
        base_branch: Optional base branch to create new branch from
        force: If True, create fresh branch and force push (for generated content)
    """
    # Ensure paths is a list and convert to strings
    if isinstance(paths, (str, Path)):
        paths = [paths]
    path_strs = [str(p) for p in paths]
    
    # Set default commit message
    if message is None:
        message = "Update files via automated commit"
    
    # Set up git config
    subprocess.run(["git", "config", "--local", "user.email", "github-actions[bot]@users.noreply.github.com"])
    subprocess.run(["git", "config", "--local", "user.name", "github-actions[bot]"])
    
    # Get current branch if none specified
    if branch is None:
        result = subprocess.run(
            ["git", "rev-parse", "--abbrev-ref", "HEAD"],
            capture_output=True,
            text=True
        )
        branch = result.stdout.strip()
        logger.info(f"Using current branch: {branch}")
    
    if force:
        # Create fresh branch from base_branch or HEAD
        base = base_branch or "HEAD"
        logger.info(f"Creating fresh branch {branch} from {base}")
        subprocess.run(["git", "checkout", "-B", branch, base])
    else:
        # Normal branch handling
        if base_branch:
            logger.info(f"Creating new branch {branch} from {base_branch}")
            subprocess.run(["git", "checkout", "-b", branch, base_branch])
        elif branch != subprocess.run(
            ["git", "rev-parse", "--abbrev-ref", "HEAD"],
            capture_output=True,
            text=True
        ).stdout.strip():
            logger.info(f"Switching to branch {branch}")
            # Try to check out existing branch, create new one if it doesn't exist
            if subprocess.run(["git", "checkout", branch], capture_output=True).returncode != 0:
                subprocess.run(["git", "checkout", "-b", branch])
            subprocess.run(["git", "pull", "origin", branch], capture_output=True)
    
    # Stage and commit changes
    subprocess.run(["git", "add", *path_strs])
    
    # Only commit if there are changes
    result = subprocess.run(
        ["git", "diff", "--staged", "--quiet"],
        capture_output=True
    )
    if result.returncode == 1:  # Changes exist
        logger.info("Committing changes")
        subprocess.run(["git", "commit", "-m", message])
        
        # Push changes
        if force:
            logger.info(f"Force pushing to {branch} branch")
            subprocess.run(["git", "push", "-f", "origin", branch])
        else:
            logger.info(f"Pushing changes to {branch} branch")
            subprocess.run(["git", "push", "origin", branch])
    else:
        logger.info("No changes to commit")



================================================================================
File: tests/conftest.py
================================================================================
# tests/conftest.py
"""Shared test fixtures."""

import pytest
from pathlib import Path
import yaml
from typing import Dict
import tempfile
import shutil

@pytest.fixture
def temp_dir():
    """Provide a clean temporary directory"""
    with tempfile.TemporaryDirectory() as td:
        yield Path(td)

@pytest.fixture
def mock_repo(temp_dir):
    """Create a mock repository structure for testing"""
    # Create basic structure
    docs_dir = temp_dir / "docs" / "readme" / "sections"
    src_dir = temp_dir / "src" / "readme_generator"
    
    docs_dir.mkdir(parents=True)
    src_dir.mkdir(parents=True)
    
    # Create mock files
    (docs_dir / "introduction.md.j2").write_text("## Introduction\n{{ test }}")
    (temp_dir / "pyproject.toml").write_text("""
[project]
name = "test-project"
version = "0.1.0"

[tool.readme]
test = "Test Value"
    """)
    
    return temp_dir

@pytest.fixture
def sample_research_yaml() -> Dict:
    """Sample research data for testing."""
    return {
        "2020": [{
            "title": "Test Paper 1",
            "first_author": "Smith",
            "arxiv_id": "2020.12345",
            "year": 2020,
            "topics": ["optimization", "training"],
            "sota": [
                "Use gradient clipping with threshold 1.0",
                "Scale learning rate with batch size"
            ],
            "models": ["model1", "model2"]
        }],
        "2021": [{
            "title": "Test Paper 2",
            "first_author": "Jones",
            "arxiv_id": "2021.67890",
            "year": 2021,
            "topics": ["attention"],
            "sota": ["Use flash attention for better memory efficiency"],
            "experimental": True
        }, {
            "title": "Test Paper 3",
            "first_author": "Smith",
            "year": 2021,
            "topics": ["optimization"],
            "sota": ["Old recommendation"],
            "attic": {
                "superseded_by": "2021.99999"
            }
        }]
    }

@pytest.fixture
def sample_yaml_file(tmp_path, sample_research_yaml):
    """Create a sample YAML file for testing."""
    yaml_path = tmp_path / "research.yaml"
    with open(yaml_path, 'w') as f:
        yaml.safe_dump(sample_research_yaml, f)
    return yaml_path

@pytest.fixture
def id_registry(tmp_path):
    """Fixture providing a fresh identifier registry."""
    from scripts.registry.identifiers import MLRIdentifierRegistry
    return MLRIdentifierRegistry(tmp_path / "test_mlr_registry.json")

@pytest.fixture
def registry(id_registry):
    """Fixture providing a fresh recommendation registry."""
    from scripts.registry.recommendations import RecommendationRegistry
    return RecommendationRegistry(id_registry)

@pytest.fixture
def populated_registry(registry, sample_research_yaml):
    """Fixture providing a registry populated with sample data."""
    from scripts.registry.recommendations import build_registry_from_yaml
    return build_registry_from_yaml(sample_research_yaml)



================================================================================
File: tests/registry/test_identifiers.py
================================================================================
# tests/registry/test_identifiers.py
"""Tests for MLR identifier generation and management."""

import pytest
from pathlib import Path
from scripts.registry.identifiers import MLRIdentifierRegistry

@pytest.fixture
def temp_registry_file(tmp_path):
    """Provide a temporary registry file path."""
    return tmp_path / "test_registry.json"

@pytest.fixture
def identifier_registry(temp_registry_file):
    """Provide a fresh identifier registry."""
    return MLRIdentifierRegistry(temp_registry_file)

def test_initialization(temp_registry_file):
    """Test registry initialization."""
    registry = MLRIdentifierRegistry(temp_registry_file)
    assert registry.current_ids == {'paper_ids': {}, 'recommendation_ids': {}}
    assert isinstance(registry.author_counters, dict)

def test_paper_id_generation(identifier_registry):
    """Test paper ID generation and consistency."""
    # Test first paper ID generation
    paper_id1 = identifier_registry.get_paper_id("Smith", 2020, "2020.12345")
    assert paper_id1 == "Smith001"
    
    # Test same author, different paper
    paper_id2 = identifier_registry.get_paper_id("Smith", 2020, "2020.99999")
    assert paper_id2 == "Smith002"
    
    # Test different author
    paper_id3 = identifier_registry.get_paper_id("Jones", 2020, "2020.54321")
    assert paper_id3 == "Jones001"
    
    # Test ID consistency
    assert identifier_registry.get_paper_id("Smith", 2020, "2020.12345") == "Smith001"

def test_mlr_id_generation(identifier_registry):
    """Test MLR ID generation."""
    # Test first recommendation ID
    mlr_id1 = identifier_registry.generate_id(2020, "Smith001")
    assert mlr_id1 == "MLR-2020-Smith001-0001"
    
    # Test second recommendation from same paper
    mlr_id2 = identifier_registry.generate_id(2020, "Smith001")
    assert mlr_id2 == "MLR-2020-Smith001-0002"
    
    # Test ID from different paper
    mlr_id3 = identifier_registry.generate_id(2020, "Jones001")
    assert mlr_id3 == "MLR-2020-Jones001-0001"

def test_registry_persistence(temp_registry_file):
    """Test that registry state persists between instances."""
    # Create and use first registry instance
    registry1 = MLRIdentifierRegistry(temp_registry_file)
    paper_id = registry1.get_paper_id("Smith", 2020, "2020.12345")
    mlr_id = registry1.generate_id(2020, paper_id)
    
    # Create new registry instance and verify state
    registry2 = MLRIdentifierRegistry(temp_registry_file)
    assert registry2.get_paper_id("Smith", 2020, "2020.12345") == paper_id
    assert registry2.generate_id(2020, paper_id) == "MLR-2020-Smith001-0002"

def test_special_character_handling(identifier_registry):
    """Test handling of special characters in author names."""
    paper_id = identifier_registry.get_paper_id("O'Brien", 2020)
    assert paper_id == "OBrien001"
    
    paper_id2 = identifier_registry.get_paper_id("von Neumann", 2020)
    assert paper_id2 == "vonNeumann001"

def test_invalid_registry_file(tmp_path):
    """Test handling of corrupted registry file."""
    bad_file = tmp_path / "bad_registry.json"
    bad_file.write_text("invalid json")
    
    registry = MLRIdentifierRegistry(bad_file)
    assert registry.current_ids == {'paper_ids': {}, 'recommendation_ids': {}}



================================================================================
File: tests/registry/test_io.py
================================================================================
# tests/registry/test_io.py
"""Tests for registry I/O operations."""

import pytest
import yaml
from pathlib import Path

from scripts.registry.io import (
    load_research_yaml,
    save_registry,
    load_registry,
    registry_to_markdown,
    RegistryDataError
)
from scripts.registry.recommendations import RecommendationRegistry

@pytest.fixture
def sample_research_yaml(tmp_path):
    """Create a sample research YAML file."""
    yaml_path = tmp_path / "research.yaml"
    data = {
        "2020": [{
            "title": "Test Paper",
            "year": 2020,
            "first_author": "Smith",
            "arxiv_id": "2020.12345",
            "topics": ["optimization"],
            "sota": ["Test recommendation"]
        }]
    }
    
    with open(yaml_path, 'w') as f:
        yaml.safe_dump(data, f)
    
    return yaml_path

@pytest.fixture
def sample_registry():
    """Create a sample registry with some recommendations."""
    registry = RecommendationRegistry()
    registry.add_recommendation(
        topic="optimization",
        recommendation="Test recommendation",
        first_author="Smith",
        source_paper="Smith et al. (2020)",
        year=2020,
        arxiv_id="2020.12345"
    )
    return registry

def test_load_research_yaml(sample_research_yaml):
    """Test loading research data from YAML."""
    data = load_research_yaml(sample_research_yaml)
    assert "2020" in data
    assert len(data["2020"]) == 1
    assert data["2020"][0]["title"] == "Test Paper"

def test_load_research_yaml_invalid_year(tmp_path):
    """Test loading YAML with invalid year."""
    yaml_path = tmp_path / "invalid.yaml"
    data = {"3000": [{"title": "Future Paper", "first_author": "Smith"}]}
    
    with open(yaml_path, 'w') as f:
        yaml.safe_dump(data, f)
    
    with pytest.raises(RegistryDataError):
        load_research_yaml(yaml_path)

def test_load_research_yaml_missing_fields(tmp_path):
    """Test loading YAML with missing required fields."""
    yaml_path = tmp_path / "invalid.yaml"
    data = {"2020": [{"title": "Incomplete Paper"}]}  # Missing first_author
    
    with open(yaml_path, 'w') as f:
        yaml.safe_dump(data, f)
    
    with pytest.raises(RegistryDataError):
        load_research_yaml(yaml_path)

def test_save_and_load_registry(sample_registry, tmp_path):
    """Test saving and loading registry."""
    registry_path = tmp_path / "registry.yaml"
    
    # Save registry
    save_registry(sample_registry, registry_path)
    assert registry_path.exists()
    
    # Load registry
    data = load_registry(registry_path)
    assert 'metadata' in data
    assert 'recommendations' in data
    assert 'topics' in data

def test_load_registry_invalid_format(tmp_path):
    """Test loading invalid registry format."""
    registry_path = tmp_path / "invalid.yaml"
    
    with open(registry_path, 'w') as f:
        yaml.safe_dump({"invalid": "format"}, f)
    
    with pytest.raises(RegistryDataError):
        load_registry(registry_path)

def test_registry_to_markdown(sample_registry, tmp_path):
    """Test markdown export."""
    markdown_path = tmp_path / "registry.md"
    registry_to_markdown(sample_registry, markdown_path)
    
    assert markdown_path.exists()
    content = markdown_path.read_text()
    
    # Check basic structure
    assert "# ML Training Recommendations Registry" in content
    assert "## Standard Recommendations" in content
    assert "### optimization" in content
    assert "Test recommendation" in content
    assert "## Statistics" in content

def test_nonexistent_file():
    """Test handling of nonexistent files."""
    with pytest.raises(FileNotFoundError):
        load_research_yaml("nonexistent.yaml")
    
    with pytest.raises(FileNotFoundError):
        load_registry("nonexistent.yaml")

def test_invalid_yaml(tmp_path):
    """Test handling of invalid YAML."""
    invalid_yaml = tmp_path / "invalid.yaml"
    invalid_yaml.write_text("invalid: yaml: content:")
    
    with pytest.raises(yaml.YAMLError):
        load_research_yaml(invalid_yaml)



================================================================================
File: tests/registry/test_recommendations.py
================================================================================
# tests/registry/test_recommendations.py
"""Tests for recommendation registry functionality."""

import pytest
from pathlib import Path
from datetime import datetime

from scripts.registry.types import MLRStatus, Recommendation, Source, Evidence
from scripts.registry.recommendations import RecommendationRegistry, generate_topic_id
from scripts.registry.identifiers import MLRIdentifierRegistry

@pytest.fixture
def id_registry(tmp_path):
    """Fixture providing a fresh identifier registry."""
    return MLRIdentifierRegistry(tmp_path / "test_mlr_registry.json")

@pytest.fixture
def registry(id_registry):
    """Fixture providing a fresh recommendation registry."""
    return RecommendationRegistry(id_registry)

def test_topic_id_generation():
    """Test topic ID generation."""
    topic = "Optimization"
    rec = "Use gradient clipping with dynamic threshold"
    topic_id = generate_topic_id(topic, rec)
    assert topic_id == "optimization/use-gradient-clipping-with-dynamic"

def test_add_standard_recommendation(registry):
    """Test adding a standard recommendation."""
    mlr_id = registry.add_recommendation(
        topic="optimization",
        recommendation="Use gradient clipping",
        first_author="Smith",
        source_paper="Smith et al. (2020)",
        year=2020,
        arxiv_id="2020.12345"
    )
    
    rec = registry.get_recommendation_by_mlr(mlr_id)
    assert rec is not None
    assert rec.status == MLRStatus.STANDARD
    assert rec.topic == "optimization"
    assert rec.source.year == 2020

def test_add_experimental_recommendation(registry):
    """Test adding an experimental recommendation."""
    mlr_id = registry.add_recommendation(
        topic="attention",
        recommendation="New attention mechanism",
        first_author="Jones",
        source_paper="Jones et al. (2021)",
        year=2021,
        experimental=True
    )
    
    rec = registry.get_recommendation_by_mlr(mlr_id)
    assert rec.status == MLRStatus.EXPERIMENTAL

def test_add_deprecated_recommendation(registry):
    """Test adding a deprecated recommendation."""
    mlr_id = registry.add_recommendation(
        topic="optimization",
        recommendation="Old method",
        first_author="Brown",
        source_paper="Brown et al. (2019)",
        year=2019,
        superseded_by="MLR-2020-Smith001-0001"
    )
    
    rec = registry.get_recommendation_by_mlr(mlr_id)
    assert rec.status == MLRStatus.DEPRECATED
    assert rec.superseded_by == "MLR-2020-Smith001-0001"
    assert rec.deprecated_date is not None

def test_get_recommendations_by_status(registry):
    """Test filtering recommendations by status."""
    # Add recommendations with different statuses
    registry.add_recommendation(
        topic="optimization",
        recommendation="Standard rec",
        first_author="Smith",
        source_paper="Smith et al. (2020)",
        year=2020
    )
    
    registry.add_recommendation(
        topic="attention",
        recommendation="Experimental rec",
        first_author="Jones",
        source_paper="Jones et al. (2021)",
        year=2021,
        experimental=True
    )
    
    standard_recs = registry.get_recommendations_by_status(MLRStatus.STANDARD)
    experimental_recs = registry.get_recommendations_by_status(MLRStatus.EXPERIMENTAL)
    
    assert len(standard_recs) == 1
    assert len(experimental_recs) == 1

def test_get_recommendations_by_topic(registry):
    """Test filtering recommendations by topic."""
    # Add multiple recommendations for same topic
    registry.add_recommendation(
        topic="optimization",
        recommendation="Rec 1",
        first_author="Smith",
        source_paper="Smith et al. (2020)",
        year=2020
    )
    
    registry.add_recommendation(
        topic="optimization",
        recommendation="Rec 2",
        first_author="Jones",
        source_paper="Jones et al. (2021)",
        year=2021
    )
    
    recs = registry.get_recommendations_by_topic("optimization")
    assert len(recs) == 2
    # Check sorting by year
    assert recs[0].source.year < recs[1].source.year

# def test_topic_stats(registry):
#     """Test topic statistics generation."""
#     # Add recommendations with different statuses
#     registry.add_recommendation(
#         topic="optimization",
#         recommendation="Standard rec",
#         first_author="Smith",
#         source_paper="Smith et al. (2020)",
#         year=2020
#     )
    
#     registry.add_recommendation(
#         topic="optimization",
#         recommendation="Experimental rec",
#         first_author="Jones",
#         source_paper="Jones et al. (2021)",
#         year=2021,
#         experimental=True
#     )
    
#     stats = registry._get_topic_stats("optimization")
#     assert stats['total_count'] == 2
#     assert stats['status_counts'][MLRStatus.STANDARD.value] == 1
#     assert stats['status_counts'][MLRStatus.EXPERIMENTAL.value] == 1
#     assert stats['years']['earliest'] == 2020
#     assert stats['years']['latest'] == 2021

def test_registry_export(registry):
    """Test registry export functionality."""
    # Add recommendations with different statuses
    registry.add_recommendation(
        topic="optimization",
        recommendation="Standard rec",
        first_author="Smith",
        source_paper="Smith et al. (2020)",
        year=2020
    )
    
    registry.add_recommendation(
        topic="attention",
        recommendation="Experimental rec",
        first_author="Jones",
        source_paper="Jones et al. (2021)",
        year=2021,
        experimental=True
    )
    
    exported = registry.export_registry()
    
    # Check basic structure
    assert 'metadata' in exported
    assert 'recommendations' in exported
    assert 'topics' in exported
    assert exported['metadata']['schema_version'] == '1.0'
    
    # Check recommendations are a flat list
    assert isinstance(exported['recommendations'], list)
    assert len(exported['recommendations']) == 2
    
    # Check individual recommendations
    standard_rec = next(
        (r for r in exported['recommendations'] 
         if r['status'] == MLRStatus.STANDARD.value), 
        None
    )
    experimental_rec = next(
        (r for r in exported['recommendations'] 
         if r['status'] == MLRStatus.EXPERIMENTAL.value),
        None
    )
    
    assert standard_rec is not None
    assert experimental_rec is not None
    
    # Verify standard recommendation
    assert standard_rec['recommendation'] == "Standard rec"
    assert standard_rec['topic'] == "optimization"
    assert standard_rec['status'] == MLRStatus.STANDARD.value
    
    # Verify experimental recommendation
    assert experimental_rec['recommendation'] == "Experimental rec"
    assert experimental_rec['topic'] == "attention"
    assert experimental_rec['status'] == MLRStatus.EXPERIMENTAL.value
    
    # Check topic stats
    assert 'optimization' in exported['topics']
    assert 'attention' in exported['topics']
    assert exported['topics']['optimization']['count'] == 1
    assert exported['topics']['attention']['count'] == 1



================================================================================
File: tests/test_generate_readme.py
================================================================================
from pathlib import Path
import pytest
from scripts.readme_generator import generate_readme, get_section_templates
from scripts.utils import get_project_root, load_config

def test_load_config(mock_repo):
    """Test configuration loading"""
    config = load_config(str(mock_repo / "pyproject.toml"))
    assert config["project"]["name"] == "test-project"
    assert config["project"]["version"] == "0.1.0"

def test_project_root(mock_repo, monkeypatch):
    """Test project root detection"""
    monkeypatch.chdir(mock_repo)
    root = get_project_root()
    assert root.samefile(mock_repo)



================================================================================
File: web/index.html
================================================================================
<!-- File: web/index.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Recommendations</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lodash/4.17.21/lodash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/js-yaml/4.1.0/js-yaml.min.js"></script>
    <link rel="stylesheet" href="styles/main.css">
</head>
<body>
    <div class="page-header">
        <h1>Machine Learning Recommendations</h1>
        
        <div class="view-controls">
            <button onclick="setView('grid')">Grid View</button>
            <button onclick="setView('table')">Table View</button>
            
            <div id="activeFilters" class="filters">
            </div>
        </div>
    </div>

    <div id="recommendations" class="recommendation-grid hidden"></div>
    <div id="recommendationsTable" class="table-container"></div>

    <script src="scripts/main.js"></script>
</body>
</html>



================================================================================
File: web/scripts/main.js
================================================================================
// File: web/scripts/main.js
let recommendations = [];
let currentView = 'grid';
let currentSort = {
    column: 'topic',
    direction: 'asc'
};

async function loadData() {
    try {
        const response = await fetch('./data/registry.yaml');
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }
        const yamlText = await response.text();
        const data = jsyaml.load(yamlText);
        if (!data || !data.recommendations) {
            throw new Error('Invalid data format');
        }
        recommendations = data.recommendations;
        renderView();
    } catch (error) {
        console.error('Error loading data:', error);
        document.getElementById('recommendations').innerHTML = '<div class="error">Error loading recommendations</div>';
        document.getElementById('recommendationsTable').innerHTML = '<div class="error">Error loading recommendations</div>';
    }
}

function formatSource(source) {
    return `${source.first_author} et al. (${source.year})`;
}

function renderGrid() {
    const grid = document.getElementById('recommendations');
    if (!recommendations || recommendations.length === 0) {
        grid.innerHTML = '<div>No recommendations available</div>';
        return;
    }
    
    grid.innerHTML = recommendations
        .map(rec => `
            <div class="recommendation-card">
                <h3>${rec.topic}</h3>
                <p>${rec.recommendation}</p>
                <div>Status: ${rec.status}</div>
                <div>Source: ${formatSource(rec.source)}</div>
                ${rec.source.arxiv_id ? 
                    `<div>arXiv: <a href="https://arxiv.org/abs/${rec.source.arxiv_id}" target="_blank">${rec.source.arxiv_id}</a></div>` 
                    : ''}
            </div>
        `).join('');
}

function renderTable() {
    const table = document.getElementById('recommendationsTable');
    if (!recommendations || recommendations.length === 0) {
        table.innerHTML = '<div>No recommendations available</div>';
        return;
    }

    table.innerHTML = `
        <table>
            <thead>
                <tr>
                    <th onclick="sortBy('topic')">Topic ${getSortIndicator('topic')}</th>
                    <th onclick="sortBy('recommendation')">Recommendation ${getSortIndicator('recommendation')}</th>
                    <th onclick="sortBy('status')">Status ${getSortIndicator('status')}</th>
                    <th>Source</th>
                </tr>
            </thead>
            <tbody>
                ${recommendations.map(rec => `
                    <tr>
                        <td>${rec.topic}</td>
                        <td>${rec.recommendation}</td>
                        <td>${rec.status}</td>
                        <td>
                            ${formatSource(rec.source)}
                            ${rec.source.arxiv_id ? 
                                `<br><a href="https://arxiv.org/abs/${rec.source.arxiv_id}" target="_blank">arXiv:${rec.source.arxiv_id}</a>` 
                                : ''}
                        </td>
                    </tr>
                `).join('')}
            </tbody>
        </table>
    `;
}

function sortBy(column) {
    if (currentSort.column === column) {
        currentSort.direction = currentSort.direction === 'asc' ? 'desc' : 'asc';
    } else {
        currentSort = { column, direction: 'asc' };
    }
    
    recommendations = _.orderBy(
        recommendations,
        [column],
        [currentSort.direction]
    );
    
    renderView();
}

function getSortIndicator(column) {
    if (currentSort.column !== column) return '↕';
    return currentSort.direction === 'asc' ? '↑' : '↓';
}

function setView(view) {
    currentView = view;
    document.getElementById('recommendations').classList.toggle('hidden', view !== 'grid');
    document.getElementById('recommendationsTable').classList.toggle('hidden', view !== 'table');
    renderView();
}

function renderView() {
    if (currentView === 'grid') {
        renderGrid();
    } else {
        renderTable();
    }
}

// Initialize
loadData();



================================================================================
File: web/styles/main.css
================================================================================
/* File: frontend-html/styles/main.css */
body {
    font-family: system-ui, -apple-system, sans-serif;
    line-height: 1.5;
    margin: 0;
    padding: 20px;
}

.page-header {
    margin-bottom: 2rem;
}

.view-controls {
    display: flex;
    gap: 1rem;
    margin-bottom: 1rem;
}

.filters {
    display: flex;
    gap: 0.5rem;
    flex-wrap: wrap;
}

.recommendation-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
    gap: 1rem;
}

.recommendation-card {
    border: 1px solid #ddd;
    padding: 1rem;
    border-radius: 4px;
}

.table-container {
    width: 100%;
    overflow-x: auto;
}

table {
    width: 100%;
    border-collapse: collapse;
}

th, td {
    padding: 0.5rem;
    text-align: left;
    border-bottom: 1px solid #ddd;
}

th {
    background: #f5f5f5;
    cursor: pointer;
}

.hidden {
    display: none;
}

.sort-indicator {
    color: #999;
}

.error {
    color: #721c24;
    background-color: #f8d7da;
    border: 1px solid #f5c6cb;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 4px;
}


